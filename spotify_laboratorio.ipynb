{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfrepereyra/laboratorio/blob/main/spotify_laboratorio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhtfSZGqb222"
      },
      "source": [
        "\n",
        " **TODAS LAS IMPORTACIONES NECESARIAS**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbbLwavMq-I0",
        "outputId": "c95b7e04-b73f-4990-aa17-17b5350ed0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-VBf-ok4GsZE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import VotingClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxBdW4SQRKMQ"
      },
      "source": [
        "# 1-Elegir las características óptimas para el entrenamiento de los modelos\n",
        "\n",
        "\n",
        "necesito normalizar los datos de este csv y crear un nuevo dataframe, lo primero quitar todos los datos nulos o Nan y despues convertir todos los datos numericos a float entre 0 y 1 para poder trabajar mejor:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wJQfDnTREsg",
        "outputId": "ac6db950-1901-466b-8b16-389278e81d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0  acousticness  danceability  duration_ms    energy  \\\n",
            "0              0      0.010248      0.824826       204600  0.426363   \n",
            "1              1      0.199998      0.720418       326933  0.350081   \n",
            "2              2      0.034570      0.830626       185707  0.403987   \n",
            "3              3      0.607034      0.431555       199413  0.328723   \n",
            "4              4      0.180902      0.645012       392893  0.555533   \n",
            "...          ...           ...           ...          ...       ...   \n",
            "2012        2012      0.001062      0.535963       274404  0.932872   \n",
            "2013        2013      0.088138      0.895592       182182  0.892189   \n",
            "2014        2014      0.008610      0.597448       207200  0.935924   \n",
            "2015        2015      0.001645      0.504640       185600  0.993897   \n",
            "2016        2016      0.002821      0.375870       204520  0.915582   \n",
            "\n",
            "      instrumentalness  key  liveness  loudness  mode  speechiness     tempo  \\\n",
            "0             0.022439    2  0.153862  0.741141     1     0.514441  0.596033   \n",
            "1             0.006260    1  0.124395  0.692162     1     0.071005  0.654474   \n",
            "2             0.000240    2  0.147548  0.791369     1     0.335351  0.158539   \n",
            "3             0.522541    5  0.077247  0.544709     1     0.003784  0.225162   \n",
            "4             0.524590    5  0.442223  0.654132     0     0.058393  0.735659   \n",
            "...                ...  ...       ...       ...   ...          ...       ...   \n",
            "2012          0.002756    1  0.115976  0.902592     1     0.390844  0.158142   \n",
            "2013          0.001711    1  0.035782  0.928149     1     0.136083  0.362636   \n",
            "2014          0.004088    0  0.205430  0.934126     1     0.105814  0.596150   \n",
            "2015          0.693648    1  0.076300  0.925953     1     0.138605  0.595736   \n",
            "2016          0.000040    9  0.209640  0.819640     1     0.148695  0.829022   \n",
            "\n",
            "      time_signature   valence  target                            song_title  \\\n",
            "0               0.75  0.262432       1                              Mask Off   \n",
            "1               0.75  0.577936       1                               Redbone   \n",
            "2               0.75  0.144379       1                          Xanny Family   \n",
            "3               0.75  0.203928       1                        Master Of None   \n",
            "4               0.75  0.908065       1                        Parallel Lines   \n",
            "...              ...       ...     ...                                   ...   \n",
            "2012            0.75  0.184079       0   Like A Bitch - Kill The Noise Remix   \n",
            "2013            0.75  0.869411       0                                 Candy   \n",
            "2014            0.75  0.454659       0  Habit - Dack Janiels & Wenzday Remix   \n",
            "2015            0.75  0.614501       0                         First Contact   \n",
            "2016            0.75  0.383619       0                    I Wanna Get Better   \n",
            "\n",
            "                artist  \n",
            "0               Future  \n",
            "1     Childish Gambino  \n",
            "2               Future  \n",
            "3          Beach House  \n",
            "4          Junior Boys  \n",
            "...                ...  \n",
            "2012    Kill The Noise  \n",
            "2013    Dillon Francis  \n",
            "2014          Rain Man  \n",
            "2015        Twin Moons  \n",
            "2016         Bleachers  \n",
            "\n",
            "[2017 rows x 17 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "archivo_csv = '/content/drive/MyDrive/UPSO/laboratorio_Spotify/Canciones_Spotify.csv'\n",
        "\n",
        "#lo convertimos a df\n",
        "df = pd.read_csv(archivo_csv)\n",
        "\n",
        "#Elimino datos nulos\n",
        "df = df.dropna()\n",
        "\n",
        "#Normalizo datos numéricos entre 0 y 1\n",
        "scaler = MinMaxScaler()\n",
        "columnas_numericas = df.select_dtypes(include=['float64']).columns\n",
        "df[columnas_numericas] = scaler.fit_transform(df[columnas_numericas])\n",
        "\n",
        "#creo el nuevo df normalizado\n",
        "df_nuevo = pd.DataFrame(df)\n",
        "print(df_nuevo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Ai_FpN2m3v"
      },
      "source": [
        "#2- Separar en datos de entrenamiento y datos de prueba\n",
        "**Realizar varios modelos de Machine Learning:**\n",
        "- KNN (K-Nearest Neighbors)\n",
        "- SVM (Support Vector Machines)\n",
        "- Árbol de decisión\n",
        "- Bayes (Naive Bayes)\n",
        "- Otro modelo que crean conveniente\n",
        " divido el conjunto de datos normalizado en conjuntos de entrenamiento y prueba. quitando las columnas de artist y song title que puede dar problemas y aplico 4 modelos de machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZgpV85JY8m7",
        "outputId": "ddae3f9d-05dc-4312-a3a9-8ddedb06a317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 1.0\n",
            "KNN Accuracy: 0.8910891089108911\n",
            "Decision Tree Accuracy: 1.0\n",
            "Gaussian Naive Bayes Accuracy: 0.9900990099009901\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Elimina la columna 'song_title' y 'artist'que no son numericos\n",
        "X = df_nuevo.drop(['target', 'song_title',\"artist\"], axis=1)\n",
        "\n",
        "\n",
        "y = df_nuevo['target']\n",
        "\n",
        "# Divide el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#SVM\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(f'SVM Accuracy: {svm_accuracy}')\n",
        "\n",
        "#KNN\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(f'KNN Accuracy: {knn_accuracy}')\n",
        "\n",
        "#Árbol de decisión\n",
        "tree_model = DecisionTreeClassifier(max_depth=3)\n",
        "tree_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "tree_predictions = tree_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
        "print(f'Decision Tree Accuracy: {tree_accuracy}')\n",
        "\n",
        "\n",
        "#Naive Bayes\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "print(f'Gaussian Naive Bayes Accuracy: {nb_accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taCEZFRJ7vFL"
      },
      "source": [
        "#3-Realizar algún tipo de validación:\n",
        "- Validación Simple\n",
        "- Validación Cruzada k-fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY5Cc7SFiRPo",
        "outputId": "e12a39f3-f96b-40c8-9ae1-49a3356c8633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 1.0\n",
            "SVM Cross-Validation Scores: [0.75990099 1.         1.         1.         0.74937965]\n",
            "SVM Mean Cross-Validation Score: 0.9018561285408937\n",
            "\n",
            "KNN Accuracy: 0.8910891089108911\n",
            "KNN Cross-Validation Scores: [0.78960396 0.89356436 0.83126551 0.84615385 0.75186104]\n",
            "KNN Mean Cross-Validation Score: 0.8224897427708033\n",
            "\n",
            "Decision Tree Accuracy: 1.0\n",
            "Decision Tree Cross-Validation Scores: [0.75247525 1.         1.         1.         0.74689826]\n",
            "Decision Tree Mean Cross-Validation Score: 0.8998747021104094\n",
            "\n",
            "Gaussian Naive Bayes Accuracy: 0.9900990099009901\n",
            "Gaussian Naive Bayes Cross-Validation Scores: [0.78960396 1.         0.93548387 1.         0.77171216]\n",
            "Gaussian Naive Bayes Mean Cross-Validation Score: 0.8993599980345429\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# X = df_nuevo.drop(['target', 'song_title', 'artist'], axis=1)\n",
        "\n",
        "\n",
        "# y = df_nuevo['target']\n",
        "\n",
        "# # Divide el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modelos\n",
        "models = {\n",
        "    'SVM': SVC(kernel='linear'),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=3),\n",
        "    'Gaussian Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "# Entrenamiento y evaluación\n",
        "for model_name, model in models.items():\n",
        "    # Entrenamiento\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicciones\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Evaluación\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f'{model_name} Accuracy: {accuracy}')\n",
        "\n",
        "    # Validación Cruzada k-fold\n",
        "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(f'{model_name} Cross-Validation Scores: {cv_scores}')\n",
        "    print(f'{model_name} Mean Cross-Validation Score: {cv_scores.mean()}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQha4UHk2lpt"
      },
      "source": [
        "#4-Evaluación y análisis del rendimiento de cada modelo:\n",
        "- Matriz de confusión\n",
        "- Precisión, recall y F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0Ms7O0x_jtV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Función para mostrar la matriz de confusión en un mapa de calor\n",
        "def mostrar_matriz_confusion(conf_matrix, title):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicho')\n",
        "    plt.ylabel('Real')\n",
        "    plt.show()\n",
        "\n",
        "# Función para mostrar las métricas de clasificación\n",
        "def mostrar_metricas_clasificacion(precision, recall, f1, title):\n",
        "    labels = ['Precisión', 'Recall', 'F1-Score']\n",
        "    values = [precision, recall, f1]\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    bars = plt.bar(labels, values, color=['green', 'orange', 'blue'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Puntuación')\n",
        "\n",
        "    # Mostrar los valores de las barras\n",
        "    for bar, value in zip(bars, values):\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.02, f'{value:.2f}', fontsize=9)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Mostrar la matriz de confusión para SVM\n",
        "mostrar_matriz_confusion(svm_conf_matrix, 'Matriz de Confusión SVM')\n",
        "mostrar_metricas_clasificacion(svm_precision, svm_recall, svm_f1_score, 'Métricas de Clasificación SVM')\n",
        "\n",
        "# Mostrar la matriz de confusión para KNN\n",
        "mostrar_matriz_confusion(knn_conf_matrix, 'Matriz de Confusión KNN')\n",
        "mostrar_metricas_clasificacion(knn_precision, knn_recall, knn_f1_score, 'Métricas de Clasificación KNN')\n",
        "\n",
        "# Mostrar la matriz de confusión para Árbol de decisión\n",
        "mostrar_matriz_confusion(tree_conf_matrix, 'Matriz de Confusión Árbol de decisión')\n",
        "mostrar_metricas_clasificacion(tree_precision, tree_recall, tree_f1_score, 'Métricas de Clasificación Árbol de decisión')\n",
        "\n",
        "# Mostrar la matriz de confusión para Naive Bayes\n",
        "mostrar_matriz_confusion(nb_conf_matrix, 'Matriz de Confusión Naive Bayes')\n",
        "mostrar_metricas_clasificacion(nb_precision, nb_recall, nb_f1_score, 'Métricas de Clasificación Naive Bayes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zh8Tub5in2F"
      },
      "source": [
        "#5- Ajustar para cada uno de los modelos los hiper parámetros:\n",
        "- Grid Search\n",
        "- Random Search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5AOOqWQkDMN"
      },
      "source": [
        "##**GRID SEARCH**\n",
        "Este bloque de codigo suele tardar mucho en ejecutarse pero funciona (en vsc me tardo 3minutos) ya que que se están ajustando 18 combinaciones de hiperparámetros en un conjunto de entrenamiento dividido en 5 pliegues (folds), lo que resulta en un total de 90 ajustes (fits). Esto se debe al uso de la validación cruzada en el proceso de Grid Search. utilize 'n_jobs' en el objeto GridSearchCV' para utiliza todos los núcleos disponibles ede la pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlY0CGEHrUs-",
        "outputId": "d2b979f9-d5ef-4674-8d86-c0b2e1cf6183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros para SVM: {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
            "Mejor score para SVM: 0.9987616099071207\n",
            "Mejores parámetros para KNN: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
            "Mejor score para KNN: 0.902638309328308\n",
            "Mejores parámetros para Árbol de decisión: {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Mejor score para Árbol de decisión: 0.9987577639751553\n",
            "Mejores parámetros para Naive Bayes: {}\n",
            "Mejor score para Naive Bayes : 0.983870161336846\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "X = df_nuevo.drop(['target', 'song_title', 'artist'], axis=1)\n",
        "\n",
        "\n",
        "y = df_nuevo['target']\n",
        "\n",
        "# Divide el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modelo SVM\n",
        "svc = SVC()\n",
        "param_grid_svc = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search_svc = GridSearchCV(svc, param_grid_svc, cv=5, scoring='accuracy' , n_jobs=-1 )\n",
        "grid_search_svc.fit(X_train, y_train)\n",
        "\n",
        "# Modelo KNN\n",
        "knn = KNeighborsClassifier()\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1 )\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "\n",
        "# Modelo Árbol de decisión\n",
        "tree = DecisionTreeClassifier()\n",
        "param_grid_tree = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search_tree = GridSearchCV(tree, param_grid_tree, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_tree.fit(X_train, y_train)\n",
        "\n",
        "# Modelo Naive Bayes (Gaussian)\n",
        "nb = GaussianNB()\n",
        "param_grid_nb = {}\n",
        "grid_search_nb = GridSearchCV(nb, param_grid_nb, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_nb.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir resultados para SVM\n",
        "print(\"Mejores parámetros para SVM:\", grid_search_svc.best_params_)\n",
        "print(\"Mejor score para SVM:\", grid_search_svc.best_score_)\n",
        "\n",
        "# Imprimir resultados para KNN\n",
        "print(\"Mejores parámetros para KNN:\", grid_search_knn.best_params_)\n",
        "print(\"Mejor score para KNN:\", grid_search_knn.best_score_)\n",
        "\n",
        "# Imprimir resultados para Árbol de decisión\n",
        "print(\"Mejores parámetros para Árbol de decisión:\", grid_search_tree.best_params_)\n",
        "print(\"Mejor score para Árbol de decisión:\", grid_search_tree.best_score_)\n",
        "\n",
        "# Imprimir resultados para Naive Bayes\n",
        "print(\"Mejores parámetros para Naive Bayes:\", grid_search_nb.best_params_)\n",
        "print(\"Mejor score para Naive Bayes :\", grid_search_nb.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP2bTqQpRXnl"
      },
      "source": [
        "##**RANDOM SEARCH**\n",
        "\n",
        "random search realiza búsquedas aleatorias en el espacio de parámetros y podría ser más eficiente para un gran número de combinaciones. tambien puede tardar un poco\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7T31xcfSWMJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Definir modelos y distribuciones de parámetros para Random Search\n",
        "models_distributions = {\n",
        "    'SVM': (SVC(), {'kernel': ['linear', 'rbf', 'poly'], 'C': uniform(0.1, 10), 'gamma': ['scale', 'auto']}),\n",
        "    'KNN': (KNeighborsClassifier(), {'n_neighbors': randint(1, 20), 'weights': ['uniform', 'distance'], 'p': [1, 2]}),\n",
        "    'Árbol de decisión': (DecisionTreeClassifier(), {'max_depth': randint(1, 20), 'min_samples_split': randint(2, 20), 'min_samples_leaf': randint(1, 10)}),\n",
        "    'Naive Bayes (Gaussian)': (GaussianNB(), {})\n",
        "}\n",
        "\n",
        "# Realizar Random Search para cada modelo con paralelización\n",
        "for model_name, (model, dist) in models_distributions.items():\n",
        "    random_search = RandomizedSearchCV(model, dist, n_iter=10, scoring='f1_macro', cv=5, n_jobs=-1, random_state=42)\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Imprimir resultados para cada modelo\n",
        "    print(f\"\\nMejores parámetros para {model_name}:\", random_search.best_params_)\n",
        "    print(f\"Mejor score para {model_name}:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6-Realizar un ensamble de los modelos:\n",
        "-Votación Mayoritaria"
      ],
      "metadata": {
        "id": "7oPJsFuQ01k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# modelos entrenados\n",
        "svm_modelo = SVC(C=0.1, kernel='linear')\n",
        "knn_modelo = KNeighborsClassifier(n_neighbors=5, weights='uniform', p=2)\n",
        "tree_modelo = DecisionTreeClassifier(max_depth=5, min_samples_split=2, min_samples_leaf=1)\n",
        "nb_modelo = GaussianNB()\n",
        "\n",
        "# creo el ensamble con votación mayoritaria\n",
        "ensamble_modelo = VotingClassifier(estimators=[\n",
        "    ('svm', svm_modelo),\n",
        "    ('knn', knn_modelo),\n",
        "    ('tree', tree_modelo),\n",
        "    ('nb', nb_modelo)\n",
        "], voting='hard')\n",
        "\n",
        "# entrenar el ensamble en el conjunto de entrenamiento\n",
        "ensamble_modelo.fit(X_train, y_train)\n",
        "\n",
        "# predecir en el conjunto de prueba\n",
        "ensamble_prediccion = ensemble_model.predict(X_test)\n",
        "\n",
        "# evaluo la precisión del ensamble\n",
        "ensamble_puntaje = accuracy_score(y_test, ensamble_prediccion)\n",
        "print(f'Precisión del Ensamble (Votación Mayoritaria): {ensamble_puntaje}')"
      ],
      "metadata": {
        "id": "JgBi00y4s8vN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "5dc24e31-34ba-4e3e-ae24-62c65051ddd1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-39ad100421b3>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# entrenar el ensamble en el conjunto de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mensamble_modelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# predecir en el conjunto de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7-Evaluación y análisis del rendimiento:\n",
        "- Matriz de confusión\n",
        "- Precisión, recall y F1-score\n"
      ],
      "metadata": {
        "id": "XZgz_e-G1LtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# calculo la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, ensamble_prediccion)\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# calculo precisión, recall y F1-score\n",
        "precision = precision_score(y_test, ensamble_prediccion)\n",
        "recall = recall_score(y_test, ensamble_prediccion)\n",
        "f1 = f1_score(y_test, ensamble_prediccion)\n",
        "\n",
        "\n",
        "\n",
        "# visualizo la matriz de confusión como un heatmap\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['No Gustó (0)', 'Gustó (1)'], yticklabels=['No Gustó (0)', 'Gustó (1)'])\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Valores Reales')\n",
        "plt.title('Matriz de Confusión - Ensamble con Votación Mayoritaria')\n",
        "plt.show()\n",
        "\n",
        "print(f'Precisión: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "bp3PdEsh0Pfm",
        "outputId": "2d71d258-6547-4ffa-c30a-f59fd1f5ddff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d64e62881fdd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculo la matriz de confusión\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Matriz de Confusión:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1MwgKarNiJj9tdx-dvpxMvUn9MmclA6TN",
      "authorship_tag": "ABX9TyOlq2gc/kry+/aQdwNrBUVu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}