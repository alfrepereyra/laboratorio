{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MwgKarNiJj9tdx-dvpxMvUn9MmclA6TN",
      "authorship_tag": "ABX9TyOqULRnhQbK7Ttc9RHCcMey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfrepereyra/laboratorio/blob/main/spotify_laboratorio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "necesito normalizar los datos de este csv y crear un nuevo dataframe, lo primero quitar todos los datos nulos o Nan y despues convertir todos los datos numericos a float entre 0 y 1 para poder trabajar mejor:\n",
        "\n"
      ],
      "metadata": {
        "id": "OxBdW4SQRKMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wJQfDnTREsg",
        "outputId": "6d40bc54-3016-4a8e-9663-3ac875d5683f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0  acousticness  danceability  duration_ms    energy  \\\n",
            "0              0      0.010248      0.824826       204600  0.426363   \n",
            "1              1      0.199998      0.720418       326933  0.350081   \n",
            "2              2      0.034570      0.830626       185707  0.403987   \n",
            "3              3      0.607034      0.431555       199413  0.328723   \n",
            "4              4      0.180902      0.645012       392893  0.555533   \n",
            "...          ...           ...           ...          ...       ...   \n",
            "2012        2012      0.001062      0.535963       274404  0.932872   \n",
            "2013        2013      0.088138      0.895592       182182  0.892189   \n",
            "2014        2014      0.008610      0.597448       207200  0.935924   \n",
            "2015        2015      0.001645      0.504640       185600  0.993897   \n",
            "2016        2016      0.002821      0.375870       204520  0.915582   \n",
            "\n",
            "      instrumentalness  key  liveness  loudness  mode  speechiness     tempo  \\\n",
            "0             0.022439    2  0.153862  0.741141     1     0.514441  0.596033   \n",
            "1             0.006260    1  0.124395  0.692162     1     0.071005  0.654474   \n",
            "2             0.000240    2  0.147548  0.791369     1     0.335351  0.158539   \n",
            "3             0.522541    5  0.077247  0.544709     1     0.003784  0.225162   \n",
            "4             0.524590    5  0.442223  0.654132     0     0.058393  0.735659   \n",
            "...                ...  ...       ...       ...   ...          ...       ...   \n",
            "2012          0.002756    1  0.115976  0.902592     1     0.390844  0.158142   \n",
            "2013          0.001711    1  0.035782  0.928149     1     0.136083  0.362636   \n",
            "2014          0.004088    0  0.205430  0.934126     1     0.105814  0.596150   \n",
            "2015          0.693648    1  0.076300  0.925953     1     0.138605  0.595736   \n",
            "2016          0.000040    9  0.209640  0.819640     1     0.148695  0.829022   \n",
            "\n",
            "      time_signature   valence  target                            song_title  \\\n",
            "0               0.75  0.262432       1                              Mask Off   \n",
            "1               0.75  0.577936       1                               Redbone   \n",
            "2               0.75  0.144379       1                          Xanny Family   \n",
            "3               0.75  0.203928       1                        Master Of None   \n",
            "4               0.75  0.908065       1                        Parallel Lines   \n",
            "...              ...       ...     ...                                   ...   \n",
            "2012            0.75  0.184079       0   Like A Bitch - Kill The Noise Remix   \n",
            "2013            0.75  0.869411       0                                 Candy   \n",
            "2014            0.75  0.454659       0  Habit - Dack Janiels & Wenzday Remix   \n",
            "2015            0.75  0.614501       0                         First Contact   \n",
            "2016            0.75  0.383619       0                    I Wanna Get Better   \n",
            "\n",
            "                artist  \n",
            "0               Future  \n",
            "1     Childish Gambino  \n",
            "2               Future  \n",
            "3          Beach House  \n",
            "4          Junior Boys  \n",
            "...                ...  \n",
            "2012    Kill The Noise  \n",
            "2013    Dillon Francis  \n",
            "2014          Rain Man  \n",
            "2015        Twin Moons  \n",
            "2016         Bleachers  \n",
            "\n",
            "[2017 rows x 17 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Ruta del archivo CSV\n",
        "archivo_csv = '/content/drive/MyDrive/UPSO/laboratorio_Spotify/Canciones_Spotify.csv'\n",
        "\n",
        "# Cargar el DataFrame original desde el archivo CSV\n",
        "df = pd.read_csv(archivo_csv)\n",
        "\n",
        "# Eliminar datos nulos\n",
        "df = df.dropna()\n",
        "\n",
        "# Normalizar datos numéricos entre 0 y 1\n",
        "scaler = MinMaxScaler()\n",
        "columnas_numericas = df.select_dtypes(include=['float64']).columns\n",
        "df[columnas_numericas] = scaler.fit_transform(df[columnas_numericas])\n",
        "\n",
        "df_nuevo = pd.DataFrame(df)\n",
        "print(df_nuevo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " divido el conjunto de datos normalizado en conjuntos de entrenamiento y prueba. quitando las columnas de artist y song title que puede dar problemas y aplico 4 modelos de machine learning"
      ],
      "metadata": {
        "id": "L0Ai_FpN2m3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Elimina la columna 'song_title' y 'artist' ya que no son numericos\n",
        "X = df_nuevo.drop(['target', 'song_title',\"artist\"], axis=1)\n",
        "\n",
        "\n",
        "y = df_nuevo['target']  # Etiquetas\n",
        "\n",
        "# Divide el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. SVM (Support Vector Machines)\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(f'SVM Accuracy: {svm_accuracy}')\n",
        "\n",
        "# 2. KNN (K-Nearest Neighbors)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(f'KNN Accuracy: {knn_accuracy}')\n",
        "\n",
        "# 3. Árbol de decisión\n",
        "tree_model = DecisionTreeClassifier(max_depth=3)\n",
        "tree_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "tree_predictions = tree_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
        "print(f'Decision Tree Accuracy: {tree_accuracy}')\n",
        "\n",
        "\n",
        "#4 Naive Bayes\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "# Evaluar el rendimiento\n",
        "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "print(f'Gaussian Naive Bayes Accuracy: {nb_accuracy}')\n"
      ],
      "metadata": {
        "id": "OZgpV85JY8m7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60885d9-9a61-4561-da02-29d5a87df4cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 1.0\n",
            "KNN Accuracy: 0.8910891089108911\n",
            "Decision Tree Accuracy: 1.0\n",
            "Gaussian Naive Bayes Accuracy: 0.9900990099009901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizar algún tipo de validación:\n",
        "● Validación Simple\n",
        "● Validación Cruzada k-fold"
      ],
      "metadata": {
        "id": "taCEZFRJ7vFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Suponiendo que 'df_nuevo' contiene tus datos normalizados y 'target' es la columna de etiquetas\n",
        "# y 'song_title', 'artist' son las columnas que deseas codificar\n",
        "X = df_nuevo.drop(['target', 'song_title', 'artist'], axis=1)\n",
        "\n",
        "\n",
        "y = df_nuevo['target']  # Etiquetas\n",
        "\n",
        "# Divide el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modelos\n",
        "models = {\n",
        "    'SVM': SVC(kernel='linear'),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=3),\n",
        "    'Gaussian Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "# Entrenamiento y evaluación\n",
        "for model_name, model in models.items():\n",
        "    # Entrenamiento\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicciones\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Evaluación\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f'{model_name} Accuracy: {accuracy}')\n",
        "\n",
        "    # Validación Cruzada k-fold\n",
        "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(f'{model_name} Cross-Validation Scores: {cv_scores}')\n",
        "    print(f'{model_name} Mean Cross-Validation Score: {cv_scores.mean()}\\n')"
      ],
      "metadata": {
        "id": "sY5Cc7SFiRPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23b77c6-3270-42a2-8e7d-e6558da0d94c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 1.0\n",
            "SVM Cross-Validation Scores: [0.75990099 1.         1.         1.         0.74937965]\n",
            "SVM Mean Cross-Validation Score: 0.9018561285408937\n",
            "\n",
            "KNN Accuracy: 0.8910891089108911\n",
            "KNN Cross-Validation Scores: [0.78960396 0.89356436 0.83126551 0.84615385 0.75186104]\n",
            "KNN Mean Cross-Validation Score: 0.8224897427708033\n",
            "\n",
            "Decision Tree Accuracy: 1.0\n",
            "Decision Tree Cross-Validation Scores: [0.75247525 1.         1.         1.         0.74689826]\n",
            "Decision Tree Mean Cross-Validation Score: 0.8998747021104094\n",
            "\n",
            "Gaussian Naive Bayes Accuracy: 0.9900990099009901\n",
            "Gaussian Naive Bayes Cross-Validation Scores: [0.78960396 1.         0.93548387 1.         0.77171216]\n",
            "Gaussian Naive Bayes Mean Cross-Validation Score: 0.8993599980345429\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación y análisis del rendimiento de cada modelo:\n",
        "● Matriz de confusión\n",
        "● Precisión, recall y F1-score texto en negrita**"
      ],
      "metadata": {
        "id": "CQha4UHk2lpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Función para mostrar la matriz de confusión en un mapa de calor\n",
        "def mostrar_matriz_confusion(conf_matrix, title):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicho')\n",
        "    plt.ylabel('Real')\n",
        "    plt.show()\n",
        "\n",
        "# Función para mostrar las métricas de clasificación\n",
        "def mostrar_metricas_clasificacion(precision, recall, f1, title):\n",
        "    labels = ['Precisión', 'Recall', 'F1-Score']\n",
        "    values = [precision, recall, f1]\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    bars = plt.bar(labels, values, color=['green', 'orange', 'blue'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Puntuación')\n",
        "\n",
        "    # Mostrar los valores de las barras\n",
        "    for bar, value in zip(bars, values):\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.02, f'{value:.2f}', fontsize=9)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Mostrar la matriz de confusión para SVM\n",
        "mostrar_matriz_confusion(svm_conf_matrix, 'Matriz de Confusión SVM')\n",
        "mostrar_metricas_clasificacion(svm_precision, svm_recall, svm_f1_score, 'Métricas de Clasificación SVM')\n",
        "\n",
        "# Mostrar la matriz de confusión para KNN\n",
        "mostrar_matriz_confusion(knn_conf_matrix, 'Matriz de Confusión KNN')\n",
        "mostrar_metricas_clasificacion(knn_precision, knn_recall, knn_f1_score, 'Métricas de Clasificación KNN')\n",
        "\n",
        "# Mostrar la matriz de confusión para Árbol de decisión\n",
        "mostrar_matriz_confusion(tree_conf_matrix, 'Matriz de Confusión Árbol de decisión')\n",
        "mostrar_metricas_clasificacion(tree_precision, tree_recall, tree_f1_score, 'Métricas de Clasificación Árbol de decisión')\n",
        "\n",
        "# Mostrar la matriz de confusión para Naive Bayes\n",
        "mostrar_matriz_confusion(nb_conf_matrix, 'Matriz de Confusión Naive Bayes')\n",
        "mostrar_metricas_clasificacion(nb_precision, nb_recall, nb_f1_score, 'Métricas de Clasificación Naive Bayes')"
      ],
      "metadata": {
        "id": "l0Ms7O0x_jtV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}